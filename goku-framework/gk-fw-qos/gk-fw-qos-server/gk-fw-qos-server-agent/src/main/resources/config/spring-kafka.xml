<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
	xmlns:context="http://www.springframework.org/schema/context"
	xsi:schemaLocation="
		http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
		http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd">

	<bean id="producerProperties" class="org.springframework.beans.factory.config.PropertiesFactoryBean">
        <property name="properties">
            <props>
        		<prop key="serializer.class">kafka.serializer.DefaultEncoder</prop>
				<!-- 指定kafka节点列表，用于获取metadata，不必全部指定 -->
        		<prop key="metadata.broker.list">${metadata.broker.list}</prop>
				<!-- 指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区 -->
				<prop key="partitioner.class">com.meituan.mafka.client.producer.CustomizePartitioner</prop>
        		<!-- 是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。
        			压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。-->
				<prop key="compression.codec">0</prop>
				<!-- 如果要压缩消息，这里指定哪些topic要压缩消息，默认empty，表示不压缩。-->
				<prop key="compressed.topics"></prop>
				<!--同步还是异步发送消息，默认“sync”表同步，"async"表异步。异步可以提高发送吞吐量,
				也意味着消息将会在本地buffer中,并适时批量发送，但是也可能导致丢失未发送过去的消息-->
				<prop key="producer.type">async</prop>
				<!-- ############## 异步发送 (以下四个异步参数可选) ############## -->
				<!-- 在async模式下,当message被缓存的时间超过此值后,将会批量发送给broker,默认为5000ms
				此值和batch.num.messages协同工作.-->
				<prop key="queue.buffering.max.ms">5000</prop>
				<!-- 无论如何,producer都无法尽快的将消息发送给broker,从而导致消息在producer端大量沉积
				 此时,如果消息的条数达到阀值,将会导致producer端阻塞或者消息被抛弃，默认为10000-->
				<prop key="queue.buffering.max.messages">20000</prop>
				<!-- 如果是异步，指定每次批量发送数据量，默认为200 -->
				<prop key="batch.num.messages">200</prop>
				<!--当消息在producer端沉积的条数达到"queue.buffering.max.meesages"后
				阻塞一定时间后,队列仍然没有enqueue(producer仍然没有发送出任何消息)
				此时producer可以继续阻塞或者将消息抛弃,此timeout值用于控制"阻塞"的时间
				-1: 无阻塞超时限制,消息不会被抛弃 ,0:立即清空队列,消息被抛弃 -->
				<prop key="queue.enqueue.timeout.ms"></prop>
				<!-- ################ end ############### -->
				<!--当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数
					因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失)
					有可能导致broker接收到重复的消息,默认值为3.
					-->
				<prop key="message.send.max.retries">3</prop>
				<!--
				# producer刷新topic metada的时间间隔,producer需要知道partition leader的位置,以及当前topic的情况
				# 因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,将会立即刷新
				# (比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置额外的刷新机制，默认值600000
				-->
				<prop key="topic.metadata.refresh.interval.ms">60000</prop>
            </props>
        </property>
    </bean>
    
    <bean id="producerConfig" class="kafka.producer.ProducerConfig">
		<constructor-arg index="0" ref="producerProperties" />
	</bean>
    
	<bean id="producer" class="kafka.javaapi.producer.Producer">
		<constructor-arg index="0" ref="producerConfig" />
	</bean>
	
	<bean id="monitorSendService" class="tv.acframework.qos.server.agent.MonitorSendService"
		destroy-method="destroy">
		<property name="producer" ref="producer" />
		<property name="topic" value="${metadata.topic:qos_collect}" />
	</bean>
	
</beans>